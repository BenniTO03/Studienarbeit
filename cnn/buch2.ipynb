{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import models\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28x28 Grauwertpixel im Wertebereich von 0 bis 255\n",
    "Anzahl Klassen = Anzahl Neuronen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(images_path):\n",
    "\n",
    "    tensor_images = []\n",
    "\n",
    "    train_or_test_folder = os.listdir(images_path)\n",
    "\n",
    "    for folder in natsorted(train_or_test_folder):\n",
    "        single_folder = os.path.join(images_path, folder)\n",
    "\n",
    "        for file in os.listdir(single_folder):\n",
    "\n",
    "            # get images as tensors\n",
    "            filepath = os.path.join(single_folder, file)\n",
    "\n",
    "            if filepath.lower().endswith(('.jpeg', '.jpg')):\n",
    "                image = tf.io.read_file(filepath)\n",
    "                tensor_image = tf.io.decode_image(image, channels=3, dtype=tf.dtypes.float32)\n",
    "                tensor_image = tf.image.resize(tensor_image, [250, 250])\n",
    "                tensor_images.append(tensor_image)\n",
    "    \n",
    "    return tensor_images\n",
    "\n",
    "\n",
    "train_path_images = '../02_data_crop/train'\n",
    "train_images = get_images(train_path_images)\n",
    "\n",
    "test_path_images = '../02_data_crop//test'\n",
    "test_images = get_images(test_path_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(images_path):\n",
    "\n",
    "    tensor_label = []\n",
    "\n",
    "    train_or_test_folder = os.listdir(images_path)\n",
    "\n",
    "    for folder in natsorted(train_or_test_folder):\n",
    "        single_folder = os.path.join(images_path, folder)\n",
    "\n",
    "        for file in os.listdir(single_folder):\n",
    "            tensor_label.append(int(single_folder))\n",
    "\n",
    "\n",
    "    return tensor_label\n",
    "\n",
    "train_path_labels = '../02_data_crop/train'\n",
    "train_labels = get_images(train_path_labels)\n",
    "\n",
    "test_path_labels = '../02_data_crop//test'\n",
    "test_labels = get_images(test_path_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices((get_images(), get_label()))\n",
    "full_dataset = tf_dataset.shuffle(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape Trainingsdaten: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDimension Bild Nr. 5: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_images[\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel zu Bild Nr. 5: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_labels[\u001b[38;5;241m5\u001b[39m]))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print('Shape Trainingsdaten: {}'.format(train_images.shape))\n",
    "print('Dimension Bild Nr. 5: {}'.format(train_images[5].shape))\n",
    "print('Label zu Bild Nr. 5: {}'.format(train_labels[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden und Vorverarbeiten der Daten\n",
    "train_images = train_images.reshape(60000, 28, 28, 1)\n",
    "train_images = train_images.astype('float32')\n",
    "train_images /= 255\n",
    "\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images.astype('float32')\n",
    "test_images /= test_images\n",
    "\n",
    "train_labels = to_categorial(train_labels)\n",
    "test_labels = to_categorial(test_labels)\n",
    "\n",
    "NrTrainimages = train_images.shape[0]\n",
    "NrTestimages = test_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Trainingsdatensatz: {}'.format(train_images.shape))\n",
    "print('Testdatensatz: {}'.format(test_images.shape))\n",
    "print('Es sind {} Trainingsbilder und {} Testbilder vorhanden.'.format(NrTrainimages, NrTestimages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellung eines zufällig ausgewählten Bildes\n",
    "randindex = random.randint(0, 60000)\n",
    "plttitle = \"Trainingsbild Nr. {} \\n Klasse: {}\".format(randindex, train_labels[randindex])\n",
    "plt.imshow(train_images[randindex].reshape(28,28), cmap='gray')\n",
    "plt.title(plttitle)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Netzwerkarchitektur\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Detektion\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m), activation\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m mnist_inputshape))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential()\n",
    "\n",
    "    # Detektion\n",
    "model.add(Conv2D(32, kernel_size=(5,5), activation= 'relu', input_shape= mnist_inputshape))\n",
    "\n",
    "    # Conv_Block 2\n",
    "model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "    # Identifikation\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', name='features'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Festlegung der Verlustfunktion und Optimierung\n",
    "model.compile(loss='categorial_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainig des Models\n",
    "LOGDIR = \"D:/logs\"\n",
    "tensorboard = TensorBoard(log_dir=LOGDIR, histogram_freq=0,\n",
    "                             write_graph=True,\n",
    "                             write_images=True)\n",
    "\n",
    "# Hyperparameter\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[tensorboard],\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern\n",
    "model.save('Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' Laden des zu klassifizierenden Bildes'\n",
    "path = ''\n",
    "file = 'vogel.jpg'\n",
    "img_file = os.path.join(path,file)\n",
    "\n",
    "# Transformation in Bildgröße\n",
    "img = image.load_img(img_file, target_size =(229,229))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zusätzliche Dimension für die Batchverarbeitung der Bilder\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassifikation des Bildes\n",
    "prediction = model.predict(x)\n",
    "\n",
    "decoded = decode_predictions(prediction, top=3)[0]\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# klassifiziertes Bild mit Klassenlegende\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "pos_x, pos_y = 1, 10\n",
    "for id, lab, prob in decoded:\n",
    "    plt.text(pos_x, pos_y, 'Klasse: {} - {:.2f}%'.format(lab, prob*100),\n",
    "             fontsize=12, color='black',\n",
    "             bbox=dict(boxstyle='round', pad=0.1, fc='white'))\n",
    "    pos_y += 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
